---
title: "IRR Causal"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 



```{r}
# Load necessary libraries
library(readxl)
library(dplyr)
library(irr)
library(caret)


```



```{r}

# Read the Excel file
df <- read_excel("C:\\D\\e Health Lab projects\\Question_Answering\\LLM_Causality\\Clinican results\\Causal IRR_R4.xlsx", sheet = 1)

# Clean column names for consistent access
colnames(df) <- gsub("[: ]+", "_", colnames(df))

# Ensure Rater1 and Rater2 are factors with same levels
df <- df %>%
  mutate(
    rater1 = factor(Rater_1_Accurate_Correct_Response_Yes_No, levels = c("No", "Yes")),
    rater2 = factor(Rater_2_Accurate_Correct_Response_Yes_No, levels = c("No", "Yes")),
    rater3 = factor(Rater_3_Accurate_Correct_Response_Yes_No, levels = c("No", "Yes")),
    rater4 = factor(Rater_4_Accurate_Correct_Response_Yes_No, levels = c("No", "Yes"))
  )
df


```



```{r}
# Compute Cohen's Kappa for the full dataset
# Assume df has 3 columns: rater1, rater2, rater3
kappa_full <- kappam.fleiss(df[, c("rater1", "rater2", "rater3", "rater4")])

print(kappa_full)


```

```{r}
library(dplyr)
library(irr)

# Updated function for 3 raters using kappam.fleiss
compute_kappa <- function(subdf) {
  # Ensure only the rater columns are passed (assuming rater1, rater2, rater3)
  kappa <- kappam.fleiss(subdf[, c("rater1", "rater2", "rater3", "rater4")])$value
  return(kappa)
}

# Group by Rung and compute Fleiss' Kappa per group
kappa_by_rung <- df %>%
  group_by(Rung) %>%
  group_modify(~ data.frame(Kappa = compute_kappa(.x)))

print(kappa_by_rung)

```


```{r}
# Distribution of Yes/No for each rater
table(df$Rater_1_Accurate_Correct_Response_Yes_No)
table(df$Rater_2_Accurate_Correct_Response_Yes_No)
table(df$Rater_3_Accurate_Correct_Response_Yes_No)
table(df$Rater_4_Accurate_Correct_Response_Yes_No)
# Or combined in one step (if dplyr/tidyr is available)
library(dplyr)
library(tidyr)

df %>%
  pivot_longer(cols = starts_with("Rater_"), names_to = "Rater", values_to = "Response") %>%
  group_by(Rater, Response) %>%
  summarise(Count = n()) %>%
  tidyr::pivot_wider(names_from = Response, values_from = Count, values_fill = 0)



```


```{r}
library(ggplot2)

# Helper function to plot agreement heatmap
plot_agreement_heatmap <- function(r1, r2, label) {
  tbl <- table(r1, r2)
  df_heat <- as.data.frame(tbl)
  colnames(df_heat) <- c("Rater1", "Rater2", "Count")
  
  ggplot(df_heat, aes(x = Rater1, y = Rater2, fill = Count)) +
    geom_tile(color = "white") +
    geom_text(aes(label = Count), color = "white", size = 5) +
    scale_fill_gradient(low = "lightblue", high = "steelblue") +
    labs(title = paste("Agreement Heatmap:", label),
         x = "Rater A", y = "Rater B") +
    theme_minimal()
}

# Plot for each rater pair
plot_agreement_heatmap(df$Rater_1_Accurate_Correct_Response_Yes_No, df$Rater_2_Accurate_Correct_Response_Yes_No, "Rater 1 vs Rater 2")
plot_agreement_heatmap(df$Rater_1_Accurate_Correct_Response_Yes_No, df$Rater_3_Accurate_Correct_Response_Yes_No, "Rater 1 vs Rater 3")
plot_agreement_heatmap(df$Rater_2_Accurate_Correct_Response_Yes_No, df$Rater_3_Accurate_Correct_Response_Yes_No, "Rater 2 vs Rater 3")



```




```{r}
library(irr)

# Binary matrix for all 3 raters
binary_matrix <- data.frame(
  r1 = df$Rater_1_Accurate_Correct_Response_Yes_No,
  r2 = df$Rater_2_Accurate_Correct_Response_Yes_No,
  r3 = df$Rater_3_Accurate_Correct_Response_Yes_No,
  r4 = df$Rater_4_Accurate_Correct_Response_Yes_No,
)

# Convert to factor with consistent levels
binary_matrix <- data.frame(lapply(binary_matrix, factor, levels = c("No", "Yes")))

# Fleiss’ Kappa
fleiss_kappa <- kappam.fleiss(binary_matrix)
print(fleiss_kappa)

# Raw percentage agreement (all 3 must agree)
binary_matrix$all_agree <- with(binary_matrix, r1 == r2 & r2 == r3)
percent_agreement <- mean(binary_matrix$all_agree, na.rm = TRUE)
cat("Raw Percent Agreement (all 3 raters):", round(percent_agreement * 100, 2), "%\n")



```




```{r}
# Cohen's Kappa for Rater 1 vs Rater 2
kappa_12 <- kappa2(binary_matrix[, c("r1", "r2")])
print(kappa_12)

# Rater 1 vs Rater 3
kappa_13 <- kappa2(binary_matrix[, c("r1", "r3")])
print(kappa_13)

# Rater 2 vs Rater 3
kappa_23 <- kappa2(binary_matrix[, c("r2", "r3")])
print(kappa_23)



```







```{r}
pairwise_summary <- data.frame(
  Pair = c("R1 vs R2", "R1 vs R3", "R2 vs R3"),
  Kappa = c(kappa_12$value, kappa_13$value, kappa_23$value),
  Agreement = c(
    mean(binary_matrix$r1 == binary_matrix$r2),
    mean(binary_matrix$r1 == binary_matrix$r3),
    mean(binary_matrix$r2 == binary_matrix$r3)
  )
)

ggplot(pairwise_summary, aes(x = Agreement, y = Kappa, label = Pair)) +
  geom_point(size = 4, color = "steelblue") +
  geom_text(nudge_y = 0.02, fontface = "bold") +
  labs(title = "Kappa vs. Percent Agreement for Rater Pairs",
       x = "Percent Agreement", y = "Cohen's Kappa") +
  theme_minimal()

```

















```{r}
# Create a confusion matrix between rater1 and rater2
agreement_matrix <- table(df$rater1, df$rater2)

# Display the matrix
print(agreement_matrix)

# Add proportions if you'd like to see percentages
prop_matrix <- prop.table(agreement_matrix)
print(round(prop_matrix, 3))  # Round to 3 decimals

```

```{r}
# Create a 3D table for all three raters
agreement_cube <- table(df$rater1, df$rater2, df$rater3)

print(agreement_cube)

```



```{r}
# Count how many times all three raters gave the same rating
df$full_agreement <- with(df, rater1 == rater2 & rater2 == rater3)

# Print the count and proportion
table(df$full_agreement)
mean(df$full_agreement, na.rm = TRUE)  # Proportion of full agreement




```



```{r}

# Rater 1 vs Rater 2
table(df$rater1, df$rater2)

# Rater 1 vs Rater 3
table(df$rater1, df$rater3)

# Rater 2 vs Rater 3
table(df$rater2, df$rater3)


```

```{r}
prop.table(table(df$full_agreement)) %>% round(3)

```


```{r}
# Load required libraries
library(readxl)    # For reading Excel files
library(irr)       # For Kappa and ICC
library(psych)     # For ICC (alternative)
library(ggplot2)   # For plots
library(dplyr)
library(tidyr)

# Read and clean the data
df <- read_excel("C:\\D\\e Health Lab projects\\Question_Answering\\LLM_Causality\\Clinican results\\Causal IRR_R4.xlsx", sheet = 1)
colnames(df) <- gsub("[: ]+", "_", colnames(df))  # Replace spaces/colons with underscores for valid names

# Extract Likert ratings
rater1 <- as.numeric(df$Rater_1_Reliable_Reasoning_1_high_to_5_poor)
rater2 <- as.numeric(df$Rater_2_Reliable_Reasoning_1_high_to_5_poor)
rater3 <- as.numeric(df$Rater_3_Reliable_Reasoning_1_high_to_5_poor)

# Combine into a dataframe for analysis
ratings <- data.frame(rater1, rater2, rater3)

# Drop rows with any missing values (required for Fleiss' Kappa and ICC)
ratings_complete <- na.omit(ratings)

# -------------------------------------------------------------------
# 1. Fleiss' Kappa for 3 raters (categorical/ordinal)
# -------------------------------------------------------------------
fleiss_kappa <- kappam.fleiss(ratings_complete)
print(fleiss_kappa)

# -------------------------------------------------------------------
# 2. Pairwise Kendall’s Tau (ordinal agreement)
# -------------------------------------------------------------------
kendall_12 <- cor.test(ratings_complete$rater1, ratings_complete$rater2, method = "kendall")
kendall_13 <- cor.test(ratings_complete$rater1, ratings_complete$rater3, method = "kendall")
kendall_23 <- cor.test(ratings_complete$rater2, ratings_complete$rater3, method = "kendall")
print(kendall_12)
print(kendall_13)
print(kendall_23)

# -------------------------------------------------------------------
# 3. Pairwise Spearman’s Rho (ordinal correlation)
# -------------------------------------------------------------------
spearman_12 <- cor.test(ratings_complete$rater1, ratings_complete$rater2, method = "spearman")
spearman_13 <- cor.test(ratings_complete$rater1, ratings_complete$rater3, method = "spearman")
spearman_23 <- cor.test(ratings_complete$rater2, ratings_complete$rater3, method = "spearman")
print(spearman_12)
print(spearman_13)
print(spearman_23)

# -------------------------------------------------------------------
# 4. Intraclass Correlation Coefficient (ICC)
# ICC(2,1): Two-way random effects, absolute agreement, single measurement
# -------------------------------------------------------------------
icc_result <- icc(ratings_complete, model = "twoway", type = "agreement", unit = "single")
print(icc_result)


```

```{r}
library(ggplot2)
library(tidyr)
library(dplyr)

# Convert to long format for pairwise plots
ratings_long <- ratings %>%
  select(rater1, rater2, rater3) %>%
  pivot_longer(cols = everything(), names_to = "Rater", values_to = "Score")

# Pairwise combinations
pairs <- list(
  c("rater1", "rater2"),
  c("rater1", "rater3"),
  c("rater2", "rater3")
)

# Function to create pairwise scatter plot
plot_rater_pair <- function(r1, r2) {
  ggplot(ratings, aes_string(x = r1, y = r2)) +
    geom_jitter(width = 0.2, height = 0.2, color = "steelblue", alpha = 0.6) +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "darkred") +
    labs(title = paste("Agreement Between", toupper(r1), "and", toupper(r2)),
         x = paste(toupper(r1), "(1 = High, 5 = Poor)"),
         y = paste(toupper(r2), "(1 = High, 5 = Poor)")) +
    theme_minimal()
}

# Plot all three pairs
plot_rater_pair("rater1", "rater2")
plot_rater_pair("rater1", "rater3")
plot_rater_pair("rater2", "rater3")

```


```{r}
library(ggplot2)
library(dplyr)

# Helper function to generate heatmap for a rater pair
plot_agreement_heatmap <- function(r1, r2, label) {
  agreement_table <- table(r1, r2)
  agreement_df <- as.data.frame(agreement_table)
  colnames(agreement_df) <- c("Rater1", "Rater2", "Count")

  ggplot(agreement_df, aes(x = Rater1, y = Rater2, fill = Count)) +
    geom_tile() +
    geom_text(aes(label = Count), color = "white", size = 5) +
    scale_fill_gradient(low = "lightblue", high = "steelblue") +
    labs(title = paste("Agreement Heatmap:", label),
         x = paste(label, "- Rater 1"), y = paste(label, "- Rater 2")) +
    theme_minimal()
}

# Plot for Rater 1 vs Rater 2
plot_agreement_heatmap(rater1, rater2, "Rater 1 vs Rater 2")

# Plot for Rater 1 vs Rater 3
plot_agreement_heatmap(rater1, rater3, "Rater 1 vs Rater 3")

# Plot for Rater 2 vs Rater 3
plot_agreement_heatmap(rater2, rater3, "Rater 2 vs Rater 3")

```

```{r}
library(tidyr)
library(dplyr)
library(ggplot2)

# Prepare data in long format
ratings_long <- ratings %>%
  pivot_longer(cols = everything(), names_to = "Rater", values_to = "Score")

# Plot
ggplot(ratings_long, aes(x = factor(Score), fill = Rater)) +
  geom_bar(position = "dodge") +
  labs(title = "Rating Distribution by Rater",
       x = "Likert Score (1 = High, 5 = Poor)", y = "Count") +
  scale_fill_manual(values = c("rater1" = "#4E79A7",  
                               "rater2" = "#F28E2B",  
                               "rater3" = "#59A14F")) +
  theme_minimal()





```
```{r}
library(irr)

# Construct full ratings data frame
ratings <- data.frame(
  rater1 = as.numeric(df$Rater_1_Reliable_Reasoning_1_high_to_5_poor),
  rater2 = as.numeric(df$Rater_2_Reliable_Reasoning_1_high_to_5_poor),
  rater3 = as.numeric(df$Rater_3_Reliable_Reasoning_1_high_to_5_poor)
)

# Remove incomplete rows (ICC requires complete data)
ratings_complete <- na.omit(ratings)

# Compute ICC(2,1): Two-way random effects, absolute agreement, single rater
icc_result <- icc(ratings_complete, model = "twoway", type = "agreement", unit = "single")

# View result
print(icc_result)

```
```{r}
icc(ratings_complete, model = "twoway", type = "agreement", unit = "average")

```

```{r}
library(irr)

# Create ratings matrix with all 3 raters
ratings <- data.frame(
  rater1 = as.numeric(df$Rater_1_Reliable_Reasoning_1_high_to_5_poor),
  rater2 = as.numeric(df$Rater_2_Reliable_Reasoning_1_high_to_5_poor),
  rater3 = as.numeric(df$Rater_3_Reliable_Reasoning_1_high_to_5_poor)
)

# Remove rows with missing values
ratings_complete <- na.omit(ratings)

# ICC(3,1): Absolute agreement, single rater (fixed raters)
icc_3_1 <- icc(ratings_complete, model = "twoway", type = "agreement", unit = "single")

# ICC(3,k): Absolute agreement, average of k raters (fixed raters)
icc_3_k <- icc(ratings_complete, model = "twoway", type = "agreement", unit = "average")

# ICC(2,1): Consistency, single rater (random raters)
icc_2_1 <- icc(ratings_complete, model = "twoway", type = "consistency", unit = "single")

# ICC(2,k): Consistency, average of k raters (random raters)
icc_2_k <- icc(ratings_complete, model = "twoway", type = "consistency", unit = "average")

# Print results
print(icc_3_1)
print(icc_3_k)
print(icc_2_1)
print(icc_2_k)


```

